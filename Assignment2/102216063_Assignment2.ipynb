{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uMDyAS2qNRr1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Step 1: Download and load dataset\n",
        "url = \"/content/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "data = data.dropna()\n",
        "\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "sample_sizes = [int(len(X_balanced) * p / 100) for p in [15, 25, 35, 45, 55]]  # Adjust percentages as per formula\n",
        "samples = [pd.DataFrame(X_balanced).sample(n=size, random_state=42) for size in sample_sizes]\n",
        "sample_labels = [pd.Series(y_balanced).iloc[sample.index] for sample in samples]\n",
        "\n",
        "sampling_techniques = [\n",
        "    lambda x: x.sample(frac=0.75, random_state=42),\n",
        "    lambda x: x.sample(frac=0.65, random_state=42),\n",
        "    lambda x: x.sample(frac=0.5, random_state=42),\n",
        "    lambda x: x.sample(frac=0.3, random_state=42),\n",
        "    lambda x: x.sample(frac=0.9, random_state=42)\n",
        "]\n",
        "\n",
        "# ML models\n",
        "models = [\n",
        "    LogisticRegression(max_iter=2000, random_state=42),\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    SVC(random_state=42),\n",
        "    KNeighborsClassifier(n_neighbors=5),\n",
        "    GradientBoostingClassifier(random_state=42)\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, (sample, labels) in enumerate(zip(samples, sample_labels)):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sample, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    for j, technique in enumerate(sampling_techniques):\n",
        "        sampled_X_train = technique(X_train)\n",
        "        sampled_y_train = y_train.loc[sampled_X_train.index]\n",
        "\n",
        "        for k, model in enumerate(models):\n",
        "            model.fit(sampled_X_train, sampled_y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            results.append({\n",
        "                'Sample': f\"Sample{i+1}\",\n",
        "                'Sampling': f\"Sampling{j+1}\",\n",
        "                'Model': f\"Model{chr(77+k)}\",\n",
        "                'Accuracy': accuracy\n",
        "            })\n",
        "\n",
        "#results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "best_results = results_df.groupby(['Model', 'Sampling'])['Accuracy'].mean().reset_index()\n",
        "best_results = best_results.loc[best_results.groupby('Model')['Accuracy'].idxmax()]\n",
        "best_results.to_csv(\"best_sampling_per_model.csv\", index=False)\n",
        "\n",
        "results_df.to_csv(\"sampling_results.csv\", index=False)\n",
        "\n"
      ]
    }
  ]
}